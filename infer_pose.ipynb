{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "CURR_DIR = os.path.abspath(\"\")\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import json\n",
    "import cv2\n",
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "from cosypose.datasets.datasets_cfg import make_scene_dataset, make_object_dataset\n",
    "\n",
    "# Pose estimator\n",
    "from cosypose.lib3d.rigid_mesh_database import MeshDataBase\n",
    "from cosypose.training.pose_models_cfg import create_model_refiner, create_model_coarse\n",
    "from cosypose.training.pose_models_cfg import check_update_config as check_update_config_pose\n",
    "from cosypose.rendering.bullet_batch_renderer import BulletBatchRenderer\n",
    "from cosypose.rendering.bullet_batch_renderer import BulletSceneRenderer\n",
    "from cosypose.integrated.pose_predictor import CoarseRefinePosePredictor\n",
    "from cosypose.integrated.multiview_predictor import MultiviewScenePredictor\n",
    "from cosypose.datasets.wrappers.multiview_wrapper import MultiViewWrapper\n",
    "import cosypose.utils.tensor_collection as tc\n",
    "\n",
    "# Detection\n",
    "from cosypose.training.detector_models_cfg import create_model_detector\n",
    "from cosypose.training.detector_models_cfg import check_update_config as check_update_config_detector\n",
    "from cosypose.integrated.detector import Detector\n",
    "\n",
    "from cosypose.evaluation.pred_runner.bop_predictions import BopPredictionRunner\n",
    "\n",
    "from cosypose.utils.distributed import get_tmp_dir, get_rank\n",
    "from cosypose.utils.distributed import init_distributed_mode\n",
    "\n",
    "# Visualization\n",
    "from  cosypose.visualization.plotter import Plotter\n",
    "from cosypose.visualization.singleview import render_prediction_wrt_camera\n",
    "from bokeh.io import export_png\n",
    "from bokeh.plotting import gridplot\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.resources import INLINE\n",
    "output_notebook(INLINE)\n",
    "\n",
    "from cosypose.config import EXP_DIR, RESULTS_DIR\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def load_detector(run_id):\n",
    "    run_dir = EXP_DIR / run_id # experiments directory + detector_id\n",
    "    cfg = yaml.load((run_dir / 'config.yaml').read_text(), Loader=yaml.FullLoader)\n",
    "    cfg = check_update_config_detector(cfg)\n",
    "    label_to_category_id = cfg.label_to_category_id\n",
    "    model = create_model_detector(cfg, len(label_to_category_id))\n",
    "    ckpt = torch.load(run_dir / 'checkpoint.pth.tar')\n",
    "    ckpt = ckpt['state_dict']\n",
    "    model.load_state_dict(ckpt)\n",
    "    model = model.cuda().eval()\n",
    "    model.cfg = cfg\n",
    "    model.config = cfg\n",
    "    model = Detector(model)\n",
    "    return model   \n",
    "\n",
    "def load_pose_models(coarse_run_id, refiner_run_id=None, n_workers=8):\n",
    "    run_dir = EXP_DIR / coarse_run_id\n",
    "    cfg = yaml.load((run_dir / 'config.yaml').read_text(), Loader=yaml.FullLoader)\n",
    "    cfg = check_update_config_pose(cfg)\n",
    "    #object_ds = BOPObjectDataset(BOP_DS_DIR / 'tless/models_cad')\n",
    "    # This object stores all obj info from tless/models/cad, with mostly label and mesh path saved for each object\n",
    "    object_ds = make_object_dataset(cfg.object_ds_name)\n",
    "    print(\"Loaded objects from \", object_ds.ds_dir)\n",
    "    # Switch to an actual database, for each object we save the info and the ACTUAL mesh\n",
    "    mesh_db = MeshDataBase.from_object_ds(object_ds)\n",
    "    # Bullet renderer, takes the urdfs of the objects and then I don't know how it is used\n",
    "    renderer = BulletBatchRenderer(object_set=cfg.urdf_ds_name, n_workers=n_workers)\n",
    "    # Database converted into tensor and sent to cuda\n",
    "    mesh_db_batched= mesh_db.batched().cuda()\n",
    "\n",
    "    def load_model(run_id):\n",
    "        if run_id is None:\n",
    "            return\n",
    "        run_dir = EXP_DIR / run_id\n",
    "        cfg = yaml.load((run_dir / 'config.yaml').read_text(), Loader=yaml.FullLoader)\n",
    "        cfg = check_update_config_pose(cfg)\n",
    "        if cfg.train_refiner:\n",
    "            model = create_model_refiner(cfg, renderer=renderer, mesh_db=mesh_db_batched)\n",
    "        else:\n",
    "            model = create_model_coarse(cfg, renderer=renderer, mesh_db=mesh_db_batched)\n",
    "        # Load weights \n",
    "        ckpt = torch.load(run_dir / 'checkpoint.pth.tar')\n",
    "        ckpt = ckpt['state_dict']\n",
    "        model.load_state_dict(ckpt)\n",
    "        model = model.cuda().eval()\n",
    "        model.cfg = cfg\n",
    "        model.config = cfg\n",
    "        return model\n",
    "\n",
    "    coarse_model = load_model(coarse_run_id)\n",
    "    refiner_model = load_model(refiner_run_id)\n",
    "    model = CoarseRefinePosePredictor(coarse_model=coarse_model,\n",
    "                                      refiner_model=refiner_model)\n",
    "    return model, mesh_db\n",
    "\n",
    "def getModel(): \n",
    "    #load models\n",
    "    detector_run_id='detector-bop-ycbv-pbr--970850'\n",
    "    coarse_run_id='coarse-bop-ycbv-pbr--724183'\n",
    "    refiner_run_id='refiner-bop-ycbv-pbr--604090'\n",
    "    detector = load_detector(detector_run_id)\n",
    "    pose_predictor, mesh_db = load_pose_models(coarse_run_id=coarse_run_id,refiner_run_id=refiner_run_id,n_workers=4)\n",
    "    return detector, pose_predictor\n",
    "\n",
    "\n",
    "def inference(detector,pose_predictor,image,camera_k):\n",
    "    \n",
    "    images = torch.from_numpy(image).cuda().float().unsqueeze_(0)\n",
    "    images = images.permute(0, 3, 1, 2) / 255\n",
    "\n",
    "    cameras_k = torch.from_numpy(camera_k).cuda().float().unsqueeze_(0)\n",
    "    #2D detector, detection_th=0.1\n",
    "    print(\"started detecting object.\")\n",
    "    box_detections = detector.get_detections(images=images, one_instance_per_class=False, \n",
    "                    detection_th=0.8,output_masks=False, mask_th=0.9)\n",
    "\n",
    "    # FAKE DETECTIONS, comment this sec\n",
    "    # Boxes in 1920x1080 res\n",
    "    #bboxes =  torch.Tensor([[1570,248,1697,320],[392,680,603,914]]).cuda()\n",
    "    # Boxes in 1280x720 res\n",
    "    bboxes =  torch.Tensor([[1046,166,1132,213],[260,453,402,610]]).cuda()\n",
    "    det_infos = pd.DataFrame({'batch_im_id': [0,0], 'label': ['obj_000030','obj_000031'], 'score': [0.9,0.9]})    \n",
    "    box_detections = tc.PandasTensorCollection(\n",
    "            infos=pd.DataFrame(det_infos),\n",
    "            bboxes=bboxes.float())\n",
    "\n",
    "\n",
    "    #pose estimation\n",
    "    if len(box_detections) == 0:\n",
    "        return None, None\n",
    "    print(\"started estimating pose.\")\n",
    "    final_preds, all_preds=pose_predictor.get_predictions(images, cameras_k, detections=box_detections,\n",
    "                        n_coarse_iterations=1,n_refiner_iterations=4)\n",
    "    #print(\"inference successfully.\")\n",
    "   \n",
    "    return final_preds.cpu(), box_detections\n",
    "\n",
    "def main(tests):\n",
    "    # detector --> actual detector, loadedMaskRCNN \n",
    "    # pose_predictor --> object: (coarse,refiner) \n",
    "    detector,pose_predictor = getModel()\n",
    "    print(\"start...........................................\")\n",
    "    \n",
    "    for test in tests:\n",
    "        run_test(test, detector, pose_predictor)\n",
    "        \n",
    "def run_test(test, detector, pose_predictor):\n",
    "    img = Image.open(test['path'])\n",
    "    img = np.array(img)\n",
    "    if img.shape == (1080,1920,3):\n",
    "        img = cv2.resize(img, dsize=(1280, 720), interpolation=cv2.INTER_CUBIC)\n",
    "    camera_k = test['camera']\n",
    "    \n",
    "    #predict\n",
    "    pred, detections = inference(detector,pose_predictor,img,camera_k)\n",
    "    if pred is None:\n",
    "        return 0\n",
    "    print(\"num of pred:\",len(pred))\n",
    "    for i in range(len(pred)):\n",
    "        print(\"object \",i,\":\",pred.infos.iloc[i].label,\"\\n  detection score:\",pred.infos.iloc[i].score) #\"------\\n  pose:\",pred.poses[i].numpy(),\n",
    "\n",
    "    #Plot\n",
    "    renderer = BulletSceneRenderer()\n",
    "    plotter = Plotter()\n",
    "    size = img.shape\n",
    "    input_dim = (size[1], size[0])\n",
    "    cam = dict(\n",
    "        resolution=input_dim,\n",
    "        K=camera_k,\n",
    "        TWC=np.eye(4)\n",
    "    )\n",
    "    save_dir = CURR_DIR+'/notebooks/visuals/'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    pred_rendered = render_prediction_wrt_camera(renderer, pred, cam)\n",
    "    cv2.rectangle(img, (detections.bboxes[0][0].int().item(), detections.bboxes[0][1].int().item()), (detections.bboxes[0][2].int().item(), detections.bboxes[0][3].int().item()), color=(255,0,0), thickness=2)\n",
    "    cv2.rectangle(img, (detections.bboxes[1][0].int().item(), detections.bboxes[1][1].int().item()), (detections.bboxes[1][2].int().item(), detections.bboxes[1][3].int().item()), color=(255,0,0), thickness=2)\n",
    "    #cv2.imwrite(\"si.png\",img)\n",
    "    \n",
    "    figures = dict()\n",
    "    figures['input_im'] = plotter.plot_image(img)\n",
    "    img_det = plotter.plot_image(img)\n",
    "    figures['detections'] = plotter.plot_maskrcnn_bboxes(img_det, detections)\n",
    "    figures['pred_rendered'] = plotter.plot_image(pred_rendered)\n",
    "    figures['pred_overlay'] = plotter.plot_overlay(img, pred_rendered, mask_opacity=0.4)           \n",
    "    fig_array = [figures['input_im'], figures['detections'], figures['pred_rendered'], figures['pred_overlay']]\n",
    "    res = gridplot(fig_array, ncols=2)\n",
    "    print(\"Test name: \"+test['name'])\n",
    "    show(res)\n",
    "    #export_png(res, filename = os.path.join(save_dir, test['name']+'.png'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training images settings\n",
    "camera_0 = np.array([[585.75607,    0,      320.5 ],\\\n",
    "                        [  0,      585.75607,    240.5],\\\n",
    "                        [  0,        0,        1,     ]])\n",
    "\n",
    "# Our images\n",
    "with open(CURR_DIR+'/inputs/camera_calibration/rs455_1920.json') as file:\n",
    "    d = json.load(file)\n",
    "    camera_1 = np.array(d.get('camera_matrix'))\n",
    "\n",
    "\n",
    "camozzi ={\n",
    "    'name' :  'camozzi',\n",
    "    'camera': camera_1,\n",
    "    'path': CURR_DIR+\"/inputs/camozzi.png\"\n",
    "    }\n",
    "    \n",
    "test0 ={\n",
    "    'name' :  'test',\n",
    "    'camera': camera_0,\n",
    "    'path': CURR_DIR+\"/inputs/image_test.png\"\n",
    "    }\n",
    "test1 = {\n",
    "    'name' : 'ours1',\n",
    "    'camera': camera_1,\n",
    "    'path': CURR_DIR+\"/inputs/image_rgb.png\"\n",
    "}\n",
    "\n",
    "test2 = {\n",
    "    'name' : 'ours2',\n",
    "    'camera': camera_1,\n",
    "    'path': CURR_DIR+\"/inputs/image_rgb2.png\"\n",
    "}\n",
    "test3 = {\n",
    "    'name' : 'ours3',\n",
    "    'camera': camera_1,\n",
    "    'path': CURR_DIR+\"/inputs/image_rgb3.png\"\n",
    "}\n",
    "\n",
    "test4 = {\n",
    "    'name' : 'ours4',\n",
    "    'camera': camera_1,\n",
    "    'path': CURR_DIR+\"/inputs/image_rgb4.png\"\n",
    "}\n",
    "\n",
    "test5 = {\n",
    "    'name' : 'ours5',\n",
    "    'camera': camera_1,\n",
    "    'path': CURR_DIR+\"/inputs/image_rgb5.png\"\n",
    "}\n",
    "\n",
    "main([camozzi])#, test1, test2, test3, test4])  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosypose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
